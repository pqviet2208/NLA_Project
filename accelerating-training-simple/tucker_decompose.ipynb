{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavrinti/accelerating_train/src/utils.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_state_dict = th.load(weights_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "from src.classifier import Classifier\n",
    "from src.utils import count_parameters, load_weights\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "device = \"cuda:4\"\n",
    "model.to(device)\n",
    "\n",
    "load_weights(model, \"out/accelerating_training/best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params: 41626 top: [(18432, 'conv4.weight'), (16384, 'fc1.weight'), (4608, 'conv3.weight'), (1152, 'conv2.weight'), (640, 'fc2.weight')]\n"
     ]
    }
   ],
   "source": [
    "num_params, top = count_parameters(model, return_top=True)\n",
    "print(\"num params:\", num_params, \"top:\", top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from src.dataloader import load_cifar\n",
    "\n",
    "_, eval_loader = load_cifar(train_batch_size=64, eval_batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval(model, device, eval_loader):\n",
    "    labels_true = []\n",
    "    labels_pred = []\n",
    "    for step, (data, label) in enumerate(eval_loader, start=1):\n",
    "        data = data.to(device)\n",
    "\n",
    "        with th.no_grad():\n",
    "            label_pred = model(data).argmax(axis=-1).squeeze()\n",
    "\n",
    "        labels_true.append(label.numpy())\n",
    "        labels_pred.append(label_pred.cpu().numpy())\n",
    "        \n",
    "    score = accuracy_score(np.concatenate(labels_true), np.concatenate(labels_pred))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model, device, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavrinti/.venv/lib/python3.10/site-packages/tensorly/decomposition/_tucker.py:167: Warning: Given only one int for 'rank' instead of a list of 2 modes. Using this rank for all modes.\n",
      "  warnings.warn(message, Warning)\n"
     ]
    }
   ],
   "source": [
    "from src.decomposition import tucker_decompose_model\n",
    "import tensorly as tl\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "model = tucker_decompose_model(model, linear_max_rank=50, conv_max_rank=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): Conv2d(32, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): Conv2d(55, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=50, bias=False)\n",
       "    (1): Linear(in_features=50, out_features=64, bias=True)\n",
       "  )\n",
       "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params: 43194 top: [(15840, 'conv4.1.weight'), (12800, 'fc1.0.weight'), (4608, 'conv3.weight'), (3520, 'conv4.2.weight'), (3200, 'fc1.1.weight')]\n"
     ]
    }
   ],
   "source": [
    "num_params, top = count_parameters(model, return_top=True)\n",
    "print(\"num params:\", num_params, \"top:\", top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6758"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model, device, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavrinti/accelerating_train/src/utils.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_state_dict = th.load(weights_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model.to(device)\n",
    "load_weights(model, \"out/accelerating_training/best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mavrinti/.venv/lib/python3.10/site-packages/tensorly/decomposition/_tucker.py:167: Warning: Given only one int for 'rank' instead of a list of 2 modes. Using this rank for all modes.\n",
      "  warnings.warn(message, Warning)\n"
     ]
    }
   ],
   "source": [
    "model = tucker_decompose_model(model, linear_max_rank=8, conv_max_rank=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=8, bias=False)\n",
       "    (1): Linear(in_features=8, out_features=64, bias=True)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=8, bias=False)\n",
       "    (1): Linear(in_features=8, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num params: 6634 top: [(2048, 'fc1.0.weight'), (576, 'conv2.1.weight'), (576, 'conv3.1.weight'), (576, 'conv4.1.weight'), (512, 'conv4.2.weight')]\n"
     ]
    }
   ],
   "source": [
    "num_params, top = count_parameters(model, return_top=True)\n",
    "print(\"num params:\", num_params, \"top:\", top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1217"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model, device, eval_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
